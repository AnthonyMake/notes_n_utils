import pickle, os
import datetime
import pandas as pd
import xml.etree.ElementTree as et
import datetime

import pprint
pp = pprint.PrettyPrinter(indent = 1, depth= 3)

# global paths to qsta utilities
# just in case
qstat  = '/remote/sge3/default/bin/lx-amd64/qstat'
qalter = '/remote/sge3/default/bin/lx-amd64/qalter'
# available_info = ['JB_job_number', 'JAT_prio', 'JAT_ntix', 'JB_nurg', 'JB_urg', 'JB_rrcontr', 'JB_wtcontr', 'JB_dlcontr', 'JB_name', 'JB_owner', 'JB_project', 'JB_department', 'state', 'JB_submission_time', 'tickets', 'JB_override_tickets', 'JB_jobshare', 'otickets', 'ftickets', 'stickets', 'JAT_share', 'queue_name', 'jclass_name', 'slots']


def qstat_to_file(user):
    
    file_name = 'qstat_' + user + '.xml'
    cmd = qstat + ' -u ' + user + ' -ext -urg -xml > ' + file_name
    
    try: 
        print('Attempting to run: \'' + cmd + '\'')
        os.system(cmd)
        print('xml file writen to ' + file_name)
    except:
        print('Error: the command \'' + cmd + '\' could not run, check if you have a valid qstat.' )
    

    return file_name

def qstat_from_xml(xml_file):

    # parse the xml file from a synopsys grid like
    # from a textfile generated by
    # qstat -u <some_user> -xml > some_xml_file.xml
    # 
    # returns a dict in the form:
    # {running : [{jb1_info1: ... , jb1_info2: ...,},{jb2_info1:..., jb2_info2:...}...],
    #  pending : [{jba_info1: ... , jba_info2: ...,},{jbb_info1:..., jbb_info2:...}...],}            
    # 
    # -vasquez- 

    # parse the xml file
    tree = et.parse(xml_file)
    all_jobs = tree.getroot()

    # The xml output structure for qstat has two queues
    # one with all running jobs, and another one with
    # the ending ones,
    # 
    # queue_info
    #     job_list state: running
    #         job_number 
    #         prior
    #         ...
    #     job_list state: running
    #         job_number 
    #         prior
    #         ...
    #     ...
    # job_info
    #     job_list state: pending
    #         job_number
    #         prior
    #         ...
    #     job_list state: pending
    #         ...
    #     ...
    # 
    # queue_info: contains only running jobs
    # job_info: contains only pending jobs

    qstat_dict = {}

    for queue in all_jobs:

        if queue.tag == 'queue_info':
            current_queue = 'running'
        elif queue.tag == 'job_info':
            current_queue = 'pending'
        else:
            print('Warning: we are not prepared for fields like: ' + str(queue.tag) + ' in the top level') 

        if current_queue not in qstat_dict:        
            qstat_dict[current_queue] = []

        for job_info in queue:
            
            # the job info will always be running for queue_info
            # and pending for job_info, ...i hope so 
            
            job_info_dict = {}

            for field in job_info:

                tag = field.tag    
                value = field.text

                job_info_dict[tag] = value

            
            qstat_dict[current_queue].append(job_info_dict)
                
    # pp.pprint(qstat_dict)
    return qstat_dict



def append_to_df(qstat_dict, qstat_common_df):

    # appends the jobs info found in a dict and appends it 
    # to a given common dataframe.
    # Returns the new dataframe.

    # initial transpose
    qstat_common_df = qstat_common_df.T
    now_time =  datetime.datetime.now()

    for jobs_info in qstat_dict['running']:

        #print(jobs_info.keys())-u 

        submission_time = datetime.datetime.strptime(jobs_info['JAT_start_time'], "%Y-%m-%dT%H:%M:%S.%f")
        
        tat = now_time - submission_time
        
        h_tat = str(tat.days) + 'days ' + str(tat.seconds//3600) + 'hours'
        cpu_usage = datetime.timedelta(seconds = int(jobs_info['cpu_usage']))
        h_cpu = str(cpu_usage.days) + 'd ' + str(cpu_usage.seconds//3600) + 'h'

        #print('h_cpu= ' + str(h_cpu) + ' cpu_usage= ' + str(cpu_usage.total_seconds()) + ' htat= ' + str(h_tat) + ' tat= ' + str(tat.total_seconds()))
        
        job_number = jobs_info['JB_job_number']
        
        # exit()
        job_serie = pd.Series()
        
        job_serie['start_time'] = pd.to_datetime(jobs_info['JAT_start_time'])
        job_serie['now']     = pd.Timestamp.now()
        #job_serie['util_t']    = pd.Timedelta(seconds = int(jobs_info['cpu_usage']))
        #job_serie['util'] = int(jobs_info['cpu_usage'])
        #job_serie['cpu_']    = pd.Timedelta(jobs_info['cpu_usage'])
        job_serie['name']    = jobs_info['JB_name']
        job_serie['project'] = jobs_info['JB_project']
        job_serie['owner']   = jobs_info['JB_owner']
        job_serie['state']   = jobs_info['state']

        qstat_common_df[job_number]= job_serie

    # for jobs_info in qstat_dict['pending']:

    #     submission_time = datetime.datetime.strptime(jobs_info['JB_submission_time'], "%Y-%m-%dT%H:%M:%S.%f")
    #     now_time =  datetime.datetime.now()
    #     tat = now_time - submission_time
    #     h_tat = str(tat.days) + 'days ' + str(tat.seconds//3600) + 'hours'

    #     job_number = jobs_info['JB_job_number']
        
    #     job_serie = pd.Series()
        
    #     job_serie['tat']     = tat
    #     job_serie['h_tat']   = h_tat
    #     job_serie['name']    = jobs_info['JB_name']
    #     job_serie['project'] = jobs_info['JB_project']
    #     job_serie['owner']   = jobs_info['JB_owner']
    #     job_serie['state']   = jobs_info['state']

    #     qstat_common_df[job_number]= job_serie

    # final transpose
    qstat_common_df = qstat_common_df.T

    return qstat_common_df


users = ['dcntqor6', 'dcntqor7']
qstat_common_df = pd.DataFrame()

for user in users:

    xml_file = qstat_to_file(user)
    qstat_dict = qstat_from_xml(xml_file)
    
    qstat_common_df = append_to_df(qstat_dict, qstat_common_df)


qstat_common_df.to_excel('qstat.xlsx')