#!/slowfs/dcopt105/vasquez/cnda/Conda/bin/python
 
import pickle, os, re
import datetime, subprocess
import pandas as pd
from pandas import ExcelWriter
import xml.etree.ElementTree as et
import datetime
from balancer import *
from datetime import datetime
# Mongo db
from pymongo import MongoClient
from dump_csv import draw_summary
from balancer import get_full_stat

import pprint
pp = pprint.PrettyPrinter(indent = 1, depth= 3)

# global paths to qsta utilities
# just in case
qstat  = '/remote/sge3/default/bin/lx-amd64/qstat'
qalter = '/remote/sge3/default/bin/lx-amd64/qalter'
# available_info = ['JB_job_number', 'JAT_prio', 'JAT_ntix', 'JB_nurg', 'JB_urg', 'JB_rrcontr', 'JB_wtcontr', 'JB_dlcontr', 'JB_name', 'JB_owner', 'JB_project', 'JB_department', 'state', 'JB_submission_time', 'tickets', 'JB_override_tickets', 'JB_jobshare', 'otickets', 'ftickets', 'stickets', 'JAT_share', 'queue_name', 'jclass_name', 'slots']


def get_qstat(user, farm):
    farms = {
        'gala' : 'source /remote/sge/default/galapagos/common/settings.csh; set qstat_real = qstat',
        'snps' : 'source /remote/sge/default/snps/common/settings.csh; set qstat_real = qstat',
    }

    cmd = '%s; qstat -u %s -ext -xml'%(farms[farm],user)
    cmd_obj = subprocess.run(cmd, executable= '/bin/csh',shell = True,stdout=subprocess.PIPE)    
    cmd_ret = cmd_obj.stdout.decode("utf-8")
    return cmd_ret

def qstat_from_xml(xml):

    # parse the xml file from a synopsys grid like
    # from a textfile generated by
    # qstat -u <some_user> -xml > some_xml_file.xml
    # 
    # returns a dict in the form:
    # {running : [{jb1_info1: ... , jb1_info2: ...,},{jb2_info1:..., jb2_info2:...}...],
    #  pending : [{jba_info1: ... , jba_info2: ...,},{jbb_info1:..., jbb_info2:...}...],}            
    # 
    # -vasquez- 

    if type(xml) == str:
        all_jobs = et.fromstring(xml)
    else:
        # parse the xml file
        tree = et.parse(xml)
        all_jobs = tree.getroot()

    # The xml output structure for qstat has two queues
    # one with all running jobs, and another one with
    # the ending ones,
    # 
    # queue_info
    #     job_list state: running
    #         job_number 
    #         prior
    #         ...
    #     job_list state: running
    #         job_number 
    #         prior
    #         ...
    #     ...
    # job_info
    #     job_list state: pending
    #         job_number
    #         prior
    #         ...
    #     job_list state: pending
    #         ...
    #     ...
    # 
    # queue_info: contains only running jobs
    # job_info: contains only pending jobs

    qstat_dict = {}

    for queue in all_jobs:

        if queue.tag == 'queue_info':
            current_queue = 'running'
        elif queue.tag == 'job_info':
            current_queue = 'pending'
        else:
            print('Warning: we are not prepared for fields like: ' + str(queue.tag) + ' in the top level') 

        if current_queue not in qstat_dict:        
            qstat_dict[current_queue] = []

        for job_info in queue:
            
            # the job info will always be running for queue_info
            # and pending for job_info, ...i hope so 
            
            job_info_dict = {}

            for field in job_info:

                tag = field.tag    
                value = field.text
                attrib = field.attrib

                job_info_dict['%s/%s'%(tag,attrib)] = value

            
            qstat_dict[current_queue].append(job_info_dict)
                
    # pp.pprint(qstat_dict)
    return qstat_dict

####################################################################

farm = 'gala'
le_stamp = datetime.now()

users    = 'dcntqor6 dcntqor7 antinopa alvarez estebanv mramire riquelme orellana vasquez rmorale omars andresp alvear rodr lizama castelan'
# excluded = 'full_job_name arch queue_name jclass_name health binding'.split()
excluded = ''.split()


# qalter -P batch -pe mt 4 -clears l_hard hconfig -clears l_hard minslotcpu -clears l_hard minslotmem -adds l_hard mem_free ##G <JOB_ID>

###################################33
# get the whole list of jobs

pp.pprint('Getting Qstat data...')
xml = get_qstat(users,'gala')
qstat_dict = qstat_from_xml(xml)
all_jobs = []


mem_tab = '''
1   A53 14784 15045 14 15
2   A53_ARM 11836 11660 12 11
3   A57_CPU 21274 20519 21 20
4   A57_Non_CPU 10268 13600 10 13
5   A72_CPU 15294 24222 15 24
6   A72_DS_SG_N5 5955 5954 6 6
7   A72_ID_SG_N5 3854 5135 4 5
8   A73_Non_CPU 14512 16814 14 16
9   ARCHS38_7nm 2223 3066 2 3
10 ARCHS438 14553 14286 14 14
11 ARCH_HS38_SG_N5 3020 4647 3 5
12 BART_SG_N5 2638 3531 3 3
13 BLOCK_BL 30455 30455 30 30
14 CortexM3 1246 1796 1 2
15 Deimos_VX_N5 7462 7462 7 7
16 Vega20-CB-T 14649 17666 14 17
17 Vega20-CPF-T 23279 28780 23 28
18 Vega20-DSA-T 10430 16909 10 17
19 Vega20-VGT-T 9834 12618 10 12
20 X5376 4996 8067 5 8
21 archipelago_N12_6T 2191 2965 2 3
22 dce_dchp_t 9349 9349 9 9
23 dcp212_Xm_Xttop 7753 9153 8 9
24 dcp245_SPEEDY28_TOP 2212 2534 2 2
25 dcp246_Xm_Xtmem 8811 10722 9 10
26 dcp247_VDD5_mux2 9724 9724 9 9
27 dcp270_enterprise_UPF 15553 16638 15 16
28 dcp275_archipelago 2813 4529 3 4
29 dcp276_xbar 13423 13423 13 13
30 dcp427_DWC_usb3 4698 7386 5 7
31 dcp428_DWC_ddr 3664 4659 4 5
32 dcp514_JDSIIP3A 16558 16558 16 16
33 dcp518_top 2038 2709 2 3
34 dcp519_fdeq_pnrb 20112 25343 20 25
35 dcp520_ccu_msw 2669 2669 3 3
36 dcp522_c8docsis31_rx_top 16386 18070 16 18
37 dcp564_leon3_mp_20_sset_ssink 6371 8590 6 8
38 dcp569_GORDON 5031 7542 5 7
39 dcp597_mmu_thdo 6531 6531 6 6
40 dcp599_rgx_tpu_mcu 13608 15630 13 15
41 dcp607_mpcore 5131 5832 5 6
42 dcp611_arm926ejs 1763 2500 2 2
43 dcp616_falcon_cpu 5306 5386 5 5
44 dcp630_jones 24491 27654 24 27
45 dcp631_mercer 25350 25350 25 25
46 dcp632_teague 28523 31646 28 31
47 dpx_bi_pu_rq_rs_ru_lblk 12924 12971 13 13
48 f4_brw_cisco 17065 18786 17 18
49 f4_dl2ri_cisco 9794 13596 10 13
50 rgx_rasterisation 11918 12428 12 12
51 xpc_fp 14860 14860 15 15
'''.strip().splitlines()

mem_des = {}

for lne in mem_tab:
  des_name = lne.strip().split()[1]
  pk_mem   = lne.strip().split()[-1]
  mem_des[des_name] = pk_mem

# pp.pprint(mem_des)

for name, Q in qstat_dict.items():
    for J in Q:
        job_num = J['JB_job_number/{}']        
        
        # pp.pprint(J)

        jb_dict = {
            'job_number'     : J['JB_job_number/{}'],
            'job_state'      : J['state/{}'],
            'job_name'       : J['JB_name/{}'],
            'flow'           : J['JB_name/{}'].split('%')[0] if '%' in J['JB_name/{}'] else None,
            'design'         : J['JB_name/{}'].split('%')[1] if '%' in J['JB_name/{}'] else None,
            'priority'       : J['JAT_prio/{}'],
            'owner'          : J['JB_owner/{}'],
            'submission_time': J['JB_submission_time/{}'] if 'JB_submission_time/{}' in J else None,
            'start_time'     : J['JAT_start_time/{}'] if 'JAT_start_time/{}' in J else None,
            'hconfig'        : J["hard_request/{'name': 'hconfig', 'resource_contribution': '0.000000'}"] if "hard_request/{'name': 'hconfig', 'resource_contribution': '0.000000'}" in J else None,
            'project'        : J['JB_project/{}']
        }
        
        all_jobs.append(jb_dict.copy())    

# pp.pprint(all_jobs)

## NOT IN HPD!!!

# condition = (jb['job_state'] in 'qw Rq'.split()) and ('HPD' not in jb['job_name']) and (jb['project']=='normal')

queued_jobs = [jb for jb in all_jobs if (jb['job_state'] in 'qw Rq'.split()) and (jb['project']=='normal')] 

# pp.pprint(queued_jobs)
print(len(queued_jobs), 'queued jobs in normal project')
users = {}
for j in queued_jobs:
    if j['owner'] not in users:
        users[j['owner']] = 1
    else:
        users[j['owner']] += 1

print('Jobs by user')
for user, n in users.items():
    print(user,' : ', n)
exit()

print('Going to move %s jobs to batch project. Yay!'%str(len(queued_jobs)))

success = 0

for jb in queued_jobs:
    # pp.pprint(get_full_stat(farm, jbn))
    # full_stat = get_full_stat(farm, jbn)

    if jb['design'] in mem_des:
        print(jb['job_name'],jb['owner'], jb['job_number'], jb['job_state'], mem_des[jb['design']])
        grd_cmd = 'qalter -P batch -pe mt 4 -clears l_hard hconfig -clears l_hard minslotcpu -clears l_hard minslotmem -adds l_hard mem_free %sG %s'%(mem_des[jb['design']],jb['job_number'])

        all_cmd = 'rsh -l %s localhost "source /remote/sge/default/galapagos/common/settings.csh; %s"'%(jb['owner'],grd_cmd)
        try:
            print('running \n\t%s'%all_cmd)
            os.system(all_cmd)
            success += 1
            print('%s / %s' % (str(success,len(queued_jobs))))
        except:
            print('CMD didnt work\n\t%s'%all_cmd)

    else:
        print(jb['design'], 'not in mem_Des')
    
print('\nSuccessfully moved %s out %s jobs to batch project'%(str(success),str(len(queued_jobs))))

    # exit()


# pp.pprint(queued_jobs)
